---
title: "PROJECT 2"
author: "Svetlana Voda"
date: "11/17/2022"
output: html_document
---

```{r, echo=FALSE}
setwd("C:/Users/vital/Desktop/UNIVERISTY/STAT 382/PROJECT/PROJECT2")
apps_data <-read.csv("apps_data.csv", stringsAsFactors = TRUE)

pair_apps <-read.csv("paid_apps.csv",stringsAsFactors = TRUE)

```

# TASK 2  

At significant level of 8% we conduct a Hypotheses test for Mean to find out is there enough evidence that population mean of App_size from the Google Play Store is greater than 25 MD.  

Hypotheses:  
             H0: mu = 25  
             H1: mu > 25

```{r, echo=FALSE}
t.test(apps_data$App_Size, mu=25, alternative = "greater", conf.level = 0.92)

```


From  One Sample t-test one can find that  p-value is 0.002688 and we can Reject H0 null hypotheses because p-value is less than significance level of 0.08. As conclusion  we can say that there is enough evidence that the population mean of App_Size from Google Play Store is greater than 25MB.

Also, from One Sample t-test we can see that at confidence level of 92% the Lower Confidence Bound for mean is   27.94954 < mu. The mean is 30.90238. Since 25 is not inside the interval, we can Reject H0 null hypotheses and conclude that there is enough evidence that the population mean is greater than 25 MB.

In Project 1 we determine that App_Size was not normally distributed but most of the time, we don't know about the shape of the distribution of the population, so people use the t-test regardless of whether the population distribution is normal. In general the t-test is not afraid of non-normal data so that is why we can use this test.    



# TASK 3  

To determine if the mean of Reviews is different when an app is a game or not we conduct a Hypotheses test for variance. We compare if variance  are equal or not at significance level of 7%. We perform Equal Variance Test  and Test for the Difference of Means.

Hypotheses:  
  H0: sigma^2 _game/sigma^2 _nogame = 1    
  H1: sigma^2 _game/sigma^2 _nogame is different of 1    
 
```{r, echo=FALSE}
game<-apps_data$Reviews[apps_data$Category=="GAME"]
nogame<-apps_data$Reviews[apps_data$Category !="GAME"]
var.test(game,nogame, ratio =1, alternative= "two.sided", conf.level= 0.93)

```


From test we can see that p-values is <2.2e-16  and is less than significant level, so we can Reject H0 (null hypotheses).  We can conclude that there is enough evidence of difference in the variance between game and no game reviews. So, there is evidence that the variances are Not Equal.

For difference of means we initialize mean (mu1) as game  and mean (mu2) as no game.   
*mu1 = game   
*mu2 = no game   


Hypotheses:   
  H0: mu1-mu2 = 0   
  H1: mu1- mu2 is different of 0   
  
```{r, echo=FALSE}
t.test(game, nogame, var.equal = FALSE, alternative = "two.sided", conf.level = 0.93)

```

From test we can see that P-value is 0.1021.  We Do Not Reject H0 because p-value is bigger than significance level of 0.07, and we can conclude that there is not enough evidence that the mean of Reviews for non games is different between the mean for the game.    
Also, we are 93% confident that the difference of mean is in the interval from -41347.14 and 777641.39. Since 0 is inside the interval, we Do Not Reject H0 (null hypotheses) and can conclude that there is not enough evidence that the mean is between -41347.14 and 777641.39    




# TASK 4   

To determine if Content_Rating varies by Category we perform Fisher Exact Test  to see if two variables are independent at 4% of significance level.   

```{r, echo=FALSE}
table_app_data <-xtabs(~Category + Content.Rating,data = apps_data)

```

```
Category  |Everyone  |Everyone 10+    | Mature 17+   |Teen  
----------|--------  |--------------- |------------- |---------  
FAMILY    |   69     |       6        |  2           | 11
GAME      |   14     |       4        |  6           | 17
TOOLS     |   35     |       0        |  0           | 0
         
```

Hypotheses:    
  H0: the variables are independent    
  H1: the variables are not independent   
  
  
```{r, echo=FALSE}
fisher.test(table_app_data, alternative = "two.sided")
```


From test we can see that P-value is 2.314e-09 and we can Reject H0 (null hypotheses) since P-value is less than significance level of 0.04.
So we can conclude that the experiment did establish an association and  there is enough evidence that the variable are not independent.


# TASK 5   

To predict if app Rating is using App_Size we create a simple linear model.   


* First we check what is the Pearson Correlation coefficient.



```{r, echo=FALSE}
plot(x= apps_data$App_Size, y= apps_data$Rating, xlab= "App_Size", ylab="Rating", main ="Scatterplot of Rating against App_Size")
abline(lm(apps_data$Rating~ apps_data$App_Size), col="blue")


```


The value of correlation r is `r cor(apps_data$App_Size, apps_data$Rating, method = "pearson") ` , which means there is a moderate negative linear relationship.

* Second check the assumption of Linearity

```{r, echo=FALSE}

lm.data <-lm(apps_data$Rating~apps_data$App_Size)
plot(x=apps_data$App_Size, y= lm.data$residuals)
abline(h=0, lty=2, col="red")

 
```

Analyzing plot we can see that linearity assumption is met because the points in residual plot are randomly scattered.    

* Third check Normality

```{r, echo=FALSE}
hist(lm.data$residuals,right = FALSE, col = "magenta", main = "Histogram")

```

We can say that that normality appear plausible because the histogram is bell-shaped.

```{r, echo=FALSE}
qqnorm(lm.data$residuals)
qqline(lm.data$residuals)
```

From graph we can see that it does follow reference line so data is normal.   

Hypotheses:    
  H0: Errors are normally distributed   
  H1: Errors are not normally distributed    
  
```{r,echo=FALSE}
shapiro.test(lm.data$residuals)
```
From Shapiro-Wilk Test we can see that the p-value is 0.1587 and is bigger than significance level, so we Do Not Reject H0 (null hypotheses). We can conclude that there is not enough evidence that the errors are not normally distributed. Overall this assumption is met.    


* Fourth check the assumption of Equal Variance.

```{r,echo=FALSE}
par(mar=rep(2,4))
par(mfrow = c(2,2))
plot(lm.data)
par(mfrow=c(1,1))

```

Analyzing Residual versus Fitted Values  plot we can conclude that Equal Variance assumption is not met because we can see a pattern.   

To check if overall model is significant :   

Hypotheses test:    
  H0: beta_1 = 0    
  H1: beta_1 is different of 0      

```{r,echo=FALSE}
summary(lm.data)
```

As result we see that F-statistic is 0.3495 and p-value  is 0.5552. We Do Not Reject H0 (null hypotheses) because p-value is bigger that significance level of 0.03. So, we can conclude that there is not enough evidence of a significant linear relationship between Rating and App_Size.
 
  
```{r, echo=FALSE}
lm.data <-lm(apps_data$Rating~apps_data$App_Size)

lm.data$coefficients

```

Equation of the Model is yhat= 4.3108 - 0.00035X. The value of Coefficient of Determination is 0.00215 and Coefficient of Correlation is -0.004007. At 0.215% of the variability of Rating is explained by the App_Size. Coefficient of Determination and Coefficient of Correlation  of 0 indicates that the regression predictions are not perfectly fit the data. So, if Coefficient of Determination is equal to 0, then the dependent variable cannot be predicted from the independent variable so there is no linear associations between the variables.


# TASK 6   

To predict Price by Rating and App_Size from Google Play Store we create a multiple linear regression where   
y = Price   
x1 = Rating    
x2 = App_Size   


```{r, echo=FALSE}
MLR<-lm(pair_apps$Price~pair_apps$Rating+pair_apps$App_Size)
MLR$coefficients
```

* First we check Linearity  
```{r, echo=FALSE}
par(mfrow=c(1,2))
plot(x= pair_apps$Rating, y=MLR$residuals, xlab = "Rating", ylab ="MLR$residuals" )
abline(h=0, col ="red")
plot(x= pair_apps$App_Size, y=MLR$residuals, ylab="MLR$residuals", xlab = "App_Size")
abline(h=0, col ="blue")
par(mfrow=c(1,1))

```

Both plots have fanned pattern. The linear model is not appropriate. The models predicting power decrease/increases
as the value of x increase so, linear assumption is not met.   

* Second we check Normality  

```{r, echo=FALSE}
par(mfrow = c(1,2))
hist(MLR$residuals,right = FALSE, col = "slategray1", main = "Histogram")
qqnorm(MLR$residuals, xlab = "Theoretical Quantiles", ylab = "Sample Quantile")
qqline(MLR$residuals)
par(mfrow = c(1,1))
```

Analyzing histogram we can conclude that it is skewed right so it does not appear that normality is plausible. From QQ Plot we can see that it does not follow reference line very well. Large deviation are present in the top right, so probably not normal.

Hypotheses:   
  H0: Errors are normally distributed   
  H1: Errors are not normally distributed    

  
```{r, echo=FALSE}
shapiro.test(MLR$residuals)  
```

From Shapiro-Wilk Test we can see that the p_value is very small so we Reject H0 (null hypotheses) and can conclude that there are enough evidence that the error are not normally distributed. So, overall this assumption is not met.

3. Third check if assumption of Equal Variance is met

```{r, echo=FALSE}
par(mar=rep(2,4))
par(mfrow = c(2,2))
plot(MLR)
par(mfrow = c(1,1))
```

Analyzing Residual versus Fitted Values  plot we can conclude that Equal variance are not met because we can  see a pattern and ouliers.   

To check if overall model is significant :   

```{r,echo=FALSE}
summary(MLR)
```

Hypotheses:   
  H0: beta_1 = beta_2 = 0   
  H1: At least one  beta_j  is different of 0   


As result we see that F-statistic is 2.374 and p-value is 0.09803. We Reject H0 because p-value is small and can conclude that there is enough evidence that the Rating and App_Size explain some of the variability in Price. Coefficient of Determination is 0.04287 and Adjuster R-Square is 0.02481. At 4.287% of the variability in Price is explained by the regression of Rating and Apps_Size. Because overall model is significant we have to test Rating and App_Size separately.

x1= Rating   

Hypotheses:   
  H0: beta_1 = 0   
  H1: beta_1 is different of 0   
  

From Partial T-Test Values we see that for Rating t-value is -1.330  and p-value is 0.1865 so, we Do Not Reject H0(null hypotheses) because p-value is bigger that significance level of 0.10. To conclude, there is not enough evidence that X1(Rating) is important in explaining some of the variability in Price.   

x2 = App_Size    

Hypotheses:   
  H0: beta_2 = 0   
  H1: beta_2 is different of 0   
  
From Partial T-Test Values we see that for App_Size t-value is 1.750 and p-value is 0.0831. We Reject H0(null hypotheses) because p-value  is less than significance level of 0.10. To conclude, there is enough evidence that App_Size is important in explaining the variability in Price.

# TASK 7   

To see if the mean of Reviews varies by category we conduct One-Way ANOVA at significant level of 4%   

```{r, echo=FALSE}
lm.review_by_category <-lm(apps_data$Reviews~apps_data$Category)


lm.anova_reviews <-anova(lm.review_by_category)

lm.anova_reviews

```


```{r,echo=FALSE}
#table(apps_data$Category)
residua_l <-lm.review_by_category$residuals
apps_data2<-cbind(apps_data,residua_l)
apps_data_family <-apps_data2$residua_l[apps_data2$Category == "FAMILY"]
apps_data_game <-apps_data2$residua_l[apps_data2$Category == "GAME"]
apps_data_tools <-apps_data2$residua_l[apps_data2$Category == "TOOLS"]

```

```
GAME  | FAMILY | TOOLS 
----- |------- |------ 
41    | 88     | 35

```

*Check for Normality of Residuals of each category    
* FAMILY   

```{r,echo=FALSE}
par(mfrow = c(1,2))
hist(apps_data_family, right = FALSE, main = "Residual Histogram", sub = "Family", col = "olivedrab1")
qqnorm(apps_data_family)
qqline(apps_data_family)
par(mfrow = c(1,1))
```

Analyzing histogram of Residuals of category FAMILY we can see that it is skewed right which  mean the data is not normally distributed plus multiple gaps. Form QQ Plot it does not follow the reference line very well. Large deviation are present in the top right so probable data is not normal.

Hypotheses:   
  
H0: Errors are normally distributed   
H1: Errors are not normally distributed   
```{r, echo=FALSE}
shapiro.test(apps_data_family)
```
From Shapiro-Wilk Test we can see that the p_value is small (<2.2e-16) and is smaller than significance level of 0.04 so we can Reject H0 (null hypotheses). There is enough evidence that the error is not normal. Overall conclusion is that Normality does not seems plausible.    

GAME   

```{r,echo=FALSE}
par(mfrow = c(1,2))
hist(apps_data_game, right = FALSE, main = "Residual Histogram", sub = "Game", col = "darkorange")
qqnorm(apps_data_game)  
qqline(apps_data_game)
par(mfrow = c(1,1))
```


Analyzing histogram of  Residuals of category GAME we can see that it is skewed right which  mean the data is not normally distributed plus multiple gaps. Form QQ Plot it does not follow the reference line very well. Large deviation are present in the top right so probable data is not normal.   

Hypotheses:   
  H0: Errors are normally distributed   
  H1: Errors are not normally distributed   
  
```{r, echo=FALSE}
shapiro.test(apps_data_game)
```

From Shapiro-Wilk Test we can see that the p_value is small (4.734e-12) and is smaller than significance level of 0.04 so we can Reject H0 (null hypotheses). There is enough evidence that the error is not normal. Overall conclusion is that Normality does not seems reasonable.      

TOOL   

```{r,echo=FALSE}
par(mfrow = c(1,2))
hist(apps_data_tools, right = FALSE, main = "Residual Histogram", sub = "Tools", col = "hotpink")
qqnorm(apps_data_tools)
qqline(apps_data_tools)
par(mfrow = c(1,1))
```

Analyzing histogram of Residuals of category TOOLS we can see that it is skewed right which mean the data is not normally distributed plus multiple gaps. Form QQ Plot it does not follow the reference line very well. Large deviation are present in the top right so probable data is not normal.

Hypotheses:   
  
H0: Errors are normally distributed   
H1: Errors are not normally distributed   

```{r, echo=FALSE}
shapiro.test(apps_data_tools)
```
From Shapiro-Wilk Test we can see that the p_value is small (1.435e-12) and is smaller than significance level of 0.04 so we can Reject H0 (null hypotheses). There is enough evidence that the error is not normal. Overall conclusion is that Normality does not seems reasonable.     

*Check for Equal Variance of Residuals    

Residuals versus Fitted Values Scatter plot   
```{r, echo=FALSE}
plot(lm.review_by_category$fitted.values, lm.review_by_category$residuals,
     xlab = "Predicted Reviews Values",
     ylab = "Residual",
     main = "Overall Residual Plot")
abline(h=0, lty =2)
```

From scatter plot we can see that the spread is different in each group. The equal variance assumption is not met. 

Residual versus Group Averages Boxplots  
```{r, echo=FALSE}
boxplot(apps_data2$residua_l~apps_data2$Category, xlab = "Category", ylab = "Residual", main= "Distribution of Residual by Group", col= "mediumorchid1")
abline(h=0, lty=2)    

```

From boxplot we can see presents of outliers, the range is different, looks odd.  The equal variance assumption is not met. 

var_f= variance of family    
var_g = variance of game   
var_t = variance of tools    

Hypotheses:   
  H0: var_f = var_g = var_t   
  H1: not all variance are the same   
  
```{r, echo=FALSE}
library(car) 
  
leveneTest(lm.review_by_category)
```

From Levene's Test we can see that p-value is 0.04248, we Do Not Reject H0(null hypotheses) since p-value is bigger that significance level of 0.04. There is not enough evidence for Equal Variance. So, assumption is not met.

To see if overall Model is significant we conduct Mean Model  

ANOVA Table   
```
              | Sum Sq    | Df       |  Mean Sq    |F_stat   |F_pval
--------------|-----------|----------|-------------|---------|------ 
Regression    | 4.4234e+12|    2     | 2.2117e+12  |  3.3492 |0.03758 
Errors        | 1.0632e+14|    161   | 6.6038e+11  |         |
Total         | 1.1074e+14|   163    |             |         |   

```


muF = Mean of Family   
muG = Mean of Game   
muT = Mean of Tools   

Hypotheses:   
  
  H0: muF=muG=muT      
  H1: At least one of the means is different    
  

As result we see that F-statistic is 3.3492 and p-value is 0.03758. We Reject H0(null hypotheses) because p-value is small than significance level of 0.04 and can conclude that there is enough evidence at least one mean is different. So overall model is significant.  

To see which difference are significant we perform Tukey Test.   

```{r, echo=FALSE}
an<-aov(Reviews~Category, data = apps_data)

summary(an)
TukeyHSD(an, conf.level = 0.96)
```

For GAME-FAMILY: p-value is 0.0286411. We Reject H0(null hypotheses) since p-value is less than significance level 0.04. So, this means that there is a significant difference between the GAME Mean Reviews and the FAMILY Mean Reviews.   

For TOOLS-FAMILY : p-value is 0.8080690. We Do Not Reject H0(null hypotheses) since p-value  is bigger than significance level 0.04 
So, this means that there is a not significant difference between the TOOLS Mean Reviews and the FAMILY Mean Reviews.    

For TOOLS-GAME : p-value is 0.2564046. We Reject H0 since p-value is less than significance level 0.04. So, this means that there is a significant difference between the TOOLS Mean Reviews and the GAME Mean Reviews.   

# TASK 8  

To see if the mean of Rating varies by category we conduct One-Way ANOVA at significant level of 3%   

```{r, echo=FALSE}
lm.rating_by_category <- lm(apps_data$Rating ~ apps_data$Category)
residual_2 <- lm.rating_by_category$residuals
apps_data3 <- cbind(apps_data, residual_2)
apps_data_FAMILY_rating <- apps_data3$residual_2[apps_data3$Category == "FAMILY"]
apps_data_GAME_rating <- apps_data3$residual_2[apps_data3$Category == "GAME"]
apps_data_TOOLS_rating <- apps_data3$residual_2[apps_data3$Category == "TOOLS"]

```

*Check for Normality of Residuals of each category        
* FAMILY    
```{r,echo=FALSE}
par(mfrow = c(1,2))
hist(apps_data_FAMILY_rating, right = FALSE, main= "Residual Histogram", sub = "FAMILY", xlab = "Residual", col="plum2")
qqnorm(apps_data_FAMILY_rating)
qqline(apps_data_FAMILY_rating)
par(mfrow = c(1,1))
```

Analyzing histogram of Residuals of category FAMILY we can see that it looks symmetric and bell-shaped. Normality is plausible. From QQ Plot it does follow the reference line. Probably normal distributed.

Hypotheses:   
H0: Errors are normally distributed   
H1: Errors are not normally distributed   

```{r, echo=FALSE}
shapiro.test(apps_data_FAMILY_rating)

```

From Shapiro-Wilk Test we can see that the p_value is 0.1166, so we Do Not Reject H0(null hypotheses) since p-value is bigger than significant level of 0.03. To conclude there is not enough evidence that the error is not normal. Overall it does appear that the data follow a normal distribution.   

* GAME  
```{r, echo=FALSE}
par(mfrow = c(1,2))
hist(apps_data_GAME_rating, right = FALSE, main= "Residual Histogram", sub = "GAME", xlab = "Residual", col="seagreen1")
qqnorm(apps_data_GAME_rating)
qqline(apps_data_GAME_rating)
par(mfrow = c(1,1))

```

Analyzing histogram of Residuals of category GAME we can see that it It looks symmetric and bell-shaped mean the data is  normally distributed. Form QQ Plot it does  follow the reference line, so probable data is normal.   

Hypotheses:   
H0: Errors are normally distributed   
H1: Errors are not normally distributed   
```{r, echo=FALSE}
shapiro.test(apps_data_GAME_rating)
```
From Shapiro-Wilk Test we can see that the p_value is 0.1976 so, we Do Not Reject H0(null hypotheses) since p-value is bigger than significant level of 0.03. To conclude there is not enough evidence that the error is not normal. Overall it does appear that the data follow a normal distribution.   

*TOOLS  
```{r, echo=FALSE}
par(mfrow = c(1,2))
hist(apps_data_TOOLS_rating, right = FALSE, main= "Residual Histogram", sub = "TOOLS", xlab = "Residual", col="yellowgreen")
qqnorm(apps_data_TOOLS_rating)
qqline(apps_data_TOOLS_rating)
par(mfrow = c(1,1))

```
Analyzing histogram of Residuals of category TOOLS we can see that it is skewed left which mean the data is not normally distributed. Analyzing QQ Plot we can see that it does follow the reference line,with some issues on the right top. Probable data is normal.

Hypotheses:    
  H0: Errors are normally distributed   
  H1: Errors are not normally distributed    

```{r, echo=FALSE}
shapiro.test(apps_data_TOOLS_rating) 
```

From Shapiro-Wilk Test we can see that the p_value is 0.2407 so, we Do Not Reject H0(null hypotheses) since p-value is bigger than significant level of 0.03. To conclude there is not enough evidence that the error is not normal. Overall it does appear that the data follow a normal distribution.   

*Check for Equal Variance of Residuals      

Residuals versus Fitted Values Scatterplot    
```{r, echo=FALSE}
plot(lm.rating_by_category$fitted.values, lm.rating_by_category$residuals, xlab = "Predicted Rating Values", ylab = "Residual", main = "Overall Residual Plot")
abline(h=0, lty=2)
```
From scatterplot we can see that the spread is different in each group. The equal variance assumption is not met.    

Residual versus Group Averages Boxplots   
```{r, echo=FALSE}
boxplot(apps_data3$residual_2~apps_data3$Category, 
        xlab= "Category",
        ylab = "Residual",
        main = "Distribution of Residual by Group", col="orangered")
abline(h=0, lty =2)
```
From boxplot we can see outliers are present in two category. Family and Tools group look skewed. Equal variance assumption is not met.

var_f= variance of family   
var_g = variance of game   
var_t = variance of tools    

Hypotheses:   
 H0: var_f = var_g = var_t   
 H1: Not all variance are the same  
 
```{r, echo=FALSE}
leveneTest(lm.rating_by_category)
```
From Levene's Test we can see that p-value is 0.4746, so we Do Not Reject H0 since p-value is bigger than significant level of 0.03. There is not enough evidence for equal variance. Overall assumption is not met.   

To see if overall Model is significant we conduct Mean Model 
```{r,echo=FALSE}
lm.anova_rating <- anova(lm.rating_by_category)
lm.anova_rating

```


ANOVA Table   
```
              | Sum Sq    | Df       |  Mean Sq    |F_stat   |F_pval
--------------|-----------|----------|-------------|---------|------ 
Regression    | 0.05      |    2     | 0.024986    |  0.6013 |0.5493 
Errors        | 6.69      |   161    | 0.041553    |         |
Total         | 6.74      |   163    |             |         |   

```

Hypotheses:    
  
  H0: muF=muG=muT    
  H1: at least one of the means is different    
  

As result we see that F-statistic is 0.6013 and p-value is 0.5493. We Do Not Reject H0 since p-value is bigger than significance level of 0.03 and we can conclude there is not enough evidence that at least one mean is different. So overall model is not significant.     



# TASK 9   

To test the effect of Content.Rating and Category on Price from Google Play Store we perform Two-Way ANOVA   

Intersection plot        

```{r, echo=FALSE}
lm.price <-lm(pair_apps$Price~pair_apps$Content.Rating*pair_apps$Category)
interaction.plot(x.factor = pair_apps$Content.Rating, trace.factor = pair_apps$Category, response = pair_apps$Price)

```


There appears to be an interaction present. Since there appear to be interactions present, we should not consider main effects.   


*Check the Normality of Residual Assumption 

```{r, echo=FALSE}
par(mfrow = c(1,2))
hist(lm.price$residuals, right=FALSE, main = "Residual Histogram", col= "thistle3", xlab= "Residuals")
qqnorm(lm.price$residuals)
qqline(lm.price$residuals)
par(mfrow = c(1,1))
```

Analyzing histogram of Residuals we can see that it is look symmetric , bell-shaped. Normality is plausible . From QQ Plot we can see that it does follow the reference line but there are some issues at the left bottom. So data is normal.  

Hypotheses:    
  H0: Errors are normally distributed    
  H1: Errors are not normally distributed    
  
```{r, echo =FALSE}
shapiro.test(lm.price$residuals)
```
From Shapiro-Wilk Test we can see that the p_value is 0.04457 , so we Do Not Reject H0(null hypotheses) since p-value is bigger than significant level 0.025. There is not enough evidence that the error is not normal. Overall conclusion normality is met.     



* Check the Equal Variance of Residual Assumption     

* Plot of Residuals vs Fitted Values 

```{r, echo=FALSE}
	plot(x = lm.price$fitted.values,
			 y = lm.price$residuals,
			 xlab = "Fitted / Predicted Values",
			 ylab = "Residuals",
			 main = "Plot of Residuals vs Fitted Values")
	abline(h = 0, lty = 2)
```

```{r, echo=FALSE}
par(mar=rep(2,4))
par(mfrow=c(2,2))
plot(lm.price)
par(mfrow =c(1,1))
```

The spread of the majority of the groups seems approximately the same so we conclude that equal variance assumption is met.  

```{r, echo=FALSE}
mean_price_content.rating <- tapply(pair_apps$Price, pair_apps$Content.Rating, mean)

#table(pair_apps$Content.Rating)

```

Bar graph of different Content.Rating mean

```{r, echo=FALSE}
bp1<- barplot(mean_price_content.rating, 
              xlab= "Content Rating Strategy",
              ylab=" Average Price",
              names.arg = c("Everyone", " Everyone 10+ ", "  Mature 17+ ", "Teen"), col="seagreen1")
text(bp1, mean_price_content.rating, round(mean_price_content.rating,2), cex =1,pos = 3)
```

From  histogram  we can see that category Teen has the highest average price of 5.101 forward by Mature 17+ with 3.99. The smallest group is Everyone 10+ with 3.32. 

Bar graph of different Category mean

```{r, echo=FALSE}
mean_price_category <- tapply(pair_apps$Price, pair_apps$Category, mean)

bp2<- barplot(mean_price_category, 
              xlab= "Category Strategy",
              ylab=" Average Price",
               col="yellow")

text(bp2, mean_price_category, round(mean_price_category,2), cex =1,pos = 3)
```

From the histogram we can see that the highest price by Category has EDUCATION with 5.99, HEALTH_AND_FITNESS with 5.36, WEATHER with 4.24. The lowest category is ART_AND_DESIGN with 1.99





```{r, echo=FALSE}
lm.price <-lm(pair_apps$Price~pair_apps$Content.Rating*pair_apps$Category)
anova(lm.price)
```

ANOVA Table   
```
                                            | Sum Sq  | Df  | Mean Sq |F_stat |F_pval
--------------------------------------------|---------|-----|---------|-------|------ 
pair_apps$Content.Rating                    | 19.564  | 3   | 6.5214  |2.8698 |0.04107 
pair_apps$Category                          | 45.940  | 17  | 2.7024  |1.1892 |0.29059
pair_apps$Content.Rating:pair_apps$Category | 20.178  | 2   | 10.0892 |4.4399 |0.01462
Residuals                                   | 195.427 | 86  | 2.2724  |       |   
Total                                       | 281.109 | 108 | 21.5854 |       |   

```

Let alpha_i = Content.Rating     
	# Let beta_j = Category      
	# Let (alpha beta)_{ij} = interaction of Content.Rating and Category    
	
	# Model Statement:   
	# Y_{ijk} = mu + alpha_i+ beta_j + (alpha beta)_{ij} + epsilon_{ijk}    

Hypotheses:   
  
  H0: (alpha_beta)_ij=0   
  H1: At least one (alpha_beta)_ij is different of 0   
  
From ANOVA table we see that F-statistic is 4.4399 and p-value is 0.01462, so we Reject H0 (null hypotheses) since p-value  is less than significant level 0.025. There is enough evidence that interaction are present. 
  
